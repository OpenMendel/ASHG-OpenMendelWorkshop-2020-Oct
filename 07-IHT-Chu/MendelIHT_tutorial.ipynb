{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative hard thresholding Tutorial\n",
    "\n",
    "This notebook showcase a few examples of the software [MendelIHT.jl](https://github.com/OpenMendel/MendelIHT.jl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary packages, install them if you don't have it\n",
    "using MendelIHT\n",
    "using SnpArrays\n",
    "using DataFrames\n",
    "using Distributions\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using GLM\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using BenchmarkTools\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is IHT?\n",
    "\n",
    "Iterative hard thresholding (IHT) is a sparse approximation method that performs variable selection and parameter estimation for high dimensional datasets. IHT returns a sparse model with prespecified $k \\in \\mathbb{Z}_+$ (or fewer) non-zero entries. In [MendelIHT.j](), the objective function is:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{maximize } & \\quad L(\\beta)\\\\\n",
    "\\text{subject to } & \\quad ||\\beta||_0 \\le k\n",
    "\\end{align}\n",
    "\n",
    "<img src=\"iht_schematic.png\" width=\"600\">\n",
    "\n",
    "The objective is solved via **projected gradient ascent**:\n",
    "$$\\beta_{n+1} = P_{S_k}(\\beta_n + s_n \\nabla L(\\beta_n)),$$\n",
    "where:\n",
    "+ $\\nabla L(\\beta)$ is the score (gradient) vector of loglikelihood\n",
    "+ $J(\\beta)$ is the expected information (hessian) matrix\n",
    "+ $s = \\frac{||\\nabla L(\\beta)||_2^2}{\\nabla L(\\beta)^tJ(\\beta)\\nabla L(\\beta)}$ is the step size\n",
    "+ $P_{S_k}(v)$ projects vector $v$ to sparsity set $S_k$ by setting all but the top $k$ entries to 0. \n",
    "\n",
    "See [our paper](https://www.biorxiv.org/content/10.1101/697755v2) for more details and computational tricks to do each of these efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: IHT vs logistic GWAS on UK Biobank\n",
    "\n",
    "+ Data: ~200,000 samples and ~500,000 SNPs\n",
    "+ Ran 5-fold cross validated IHT for sparsity levels 1~50, distributed to 5 computers. Each completed with 24h. Total run time $<2$ days.\n",
    "+ Found 33 significant SNPs, plotted against traditional GWAS result using [MendelPlots.jl](https://github.com/OpenMendel/MendelPlots.jl):\n",
    "\n",
    "<img src=\"manhattan.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supported GLM models and Link functions\n",
    "\n",
    "MendelIHT borrows distribution and link functions implementationed in [GLM.jl](http://juliastats.github.io/GLM.jl/stable/) and [Distributions.jl](https://juliastats.github.io/Distributions.jl/stable/).\n",
    "\n",
    "| Distribution | Canonical Link | Status |\n",
    "|:---:|:---:|:---:|\n",
    "| Normal | IdentityLink | $\\checkmark$ |\n",
    "| Bernoulli | LogitLink |$\\checkmark$ |\n",
    "| Poisson | LogLink |  $\\checkmark$ |\n",
    "| NegativeBinomial | LogLink |  $\\checkmark$ |\n",
    "| Gamma | InverseLink | experimental |\n",
    "| InverseGaussian | InverseSquareLink | experimental |\n",
    "\n",
    "Examples of these distributions in their default value is visualized in [this post](https://github.com/JuliaStats/GLM.jl/issues/289).\n",
    "\n",
    "### Available link functions\n",
    "\n",
    "    CauchitLink\n",
    "    CloglogLink\n",
    "    IdentityLink\n",
    "    InverseLink\n",
    "    InverseSquareLink\n",
    "    LogitLink\n",
    "    LogLink\n",
    "    ProbitLink\n",
    "    SqrtLink\n",
    "    \n",
    "**Note:** Adding your favorite distribution only requires implementation of loglikelihood, score, and expected information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: How to Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate example data (to be imported later)\n",
    "\n",
    "First we simulate an example PLINK trio (`.bim`, `.bed`, `.fam`) and non-genetic covariates, then we illustrate how to import them. For genotype matrix simulation, we simulate under the model:\n",
    "\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows and columns\n",
    "n = 1000\n",
    "p = 10000\n",
    "\n",
    "#random seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate random `.bed` file\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "# create accompanying `.bim`, `.fam` files (randomly generated)\n",
    "make_bim_fam_files(x, ones(n), \"./data/tmp\")\n",
    "\n",
    "# simulate non-genetic covariates (in this case, we include intercept and sex)\n",
    "z = [ones(n, 1) rand(0:1, n)]\n",
    "writedlm(\"./data/tmp_nongenetic_covariates.txt\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Genotype data and Non-Genetic Covariates from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SnpArray(\"./data/tmp.bed\")\n",
    "z = readdlm(\"./data/tmp_nongenetic_covariates.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Non-Genetic Covariates.\n",
    "\n",
    "We recommend standardizing all genetic and non-genetic covarariates (including binary and categorical), except for the intercept. This ensures equal penalization for all predictors. For genotype matrix, `SnpBitMatrix` efficiently achieves this standardization. For non-genetic covariates, we use the built-in function `standardize!`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnpBitMatrix can automatically standardizes .bed file (without extra memory) and behaves like a matrix\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true);\n",
    "\n",
    "# using view is important for correctness\n",
    "standardize!(@view(z[:, 2:end])) \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Running IHT on Quantitative Traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our model is simulated as:\n",
    "\n",
    "$$y_i \\sim \\mathbf{x}_i^T\\mathbf{\\beta} + \\epsilon_i$$\n",
    "\n",
    "$$x_{ij} \\sim \\rm Binomial(2, \\rho_j)$$\n",
    "\n",
    "$$\\rho_j \\sim \\rm Uniform(0, 0.5)$$\n",
    "\n",
    "$$\\epsilon_i \\sim \\rm N(0, 1)$$\n",
    "\n",
    "$$\\beta_i \\sim \\rm N(0, 1) \\quad (\\text{for 10 different } i)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model dimensions, true model size, distribution, and link functions\n",
    "n = 1000\n",
    "p = 10000\n",
    "k = 10\n",
    "dist = Normal\n",
    "link = canonicallink(dist())\n",
    "\n",
    "# set random seed for reproducibility\n",
    "Random.seed!(2020)\n",
    "\n",
    "# simulate SNP matrix, store the result in a file called tmp.bed\n",
    "x = simulate_random_snparray(n, p, \"./data/tmp.bed\")\n",
    "\n",
    "#construct the SnpBitMatrix type (needed for L0_reg() and simulate_random_response() below)\n",
    "xbm = SnpBitMatrix{Float64}(x, model=ADDITIVE_MODEL, center=true, scale=true); \n",
    "\n",
    "# intercept is the only nongenetic covariate\n",
    "z = ones(n, 1) \n",
    "\n",
    "# simulate response y, true model b, and the correct non-0 positions of b\n",
    "y, true_b, correct_position = simulate_random_response(x, xbm, k, dist, link);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run `q`-fold cross validation to determine best model size\n",
    "\n",
    "To run `cv_iht`, you must specify `path` and `q`, defined below:\n",
    "\n",
    "+ **`path`**: all the model sizes you wish to test.\n",
    "+ **`q`**: number of disjoint partitions of your data. \n",
    "\n",
    "By default, we partition the training/testing data randomly, but you can change this by inputing the `fold` vector as optional argument. In this example we tested $k = 5, 6, ..., 15$ across 3 fold cross validation. This is equivalent to running IHT across 30 different models, and hence, is ideal for parallel computing (which you specify by `parallel=true`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = collect(5:15)      # various sparsity levels to test (in this case 5 through 15)\n",
    "q    = 3                  # number of fold cross validation\n",
    "\n",
    "# Inputs: x, z, y = genotype matrix, other covariates, and response, 1 = group info (none)\n",
    "@time mses = cv_iht(Normal(), IdentityLink(), x, z, y, 1, path, q, parallel=false); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(path, mses, label=\"Mean Squared Error\", xlabel=\"Sparsity level\", \n",
    "        ylabel=\"Mean Squared Error\", linewidth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run IHT on full model for best estimated k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = path[argmin(mses)]                                        # k = 7 minimizes MSE\n",
    "result = L0_reg(x, xbm, z, y, 1, best_k, Normal(), IdentityLink()) # run IHT on full data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check final model against simulation\n",
    "\n",
    "Since all our data and model was simulated, we can see how well `cv_iht` combined with `L0_reg` estimated the true model. For this example, we find that IHT found every simulated predictor, with 0 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model = DataFrame(\n",
    "    true_β      = true_b[correct_position], \n",
    "    estimated_β = result.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** IHT found 7/10 true predictors, with superb parameter estimates. The remaining 3 predictors cannot be identified by IHT because they have very small effect sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Negative Binomial regression with group information \n",
    "\n",
    "Now we show how to include group information to perform **doubly sparse** projections. This results in a model with at most $j$ groups where each group contains at most $k$ SNPs. This is useful for:\n",
    "\n",
    "+ Data with extensive LD blocks (i.e. correlated covariates)\n",
    "+ Prior knowledge on genes/pathways\n",
    "\n",
    "## Simulation: IHT on extensive LD blocks\n",
    "In this example, we simulated:\n",
    "+ 10,000 SNPs, each belonging to 1 of 500 disjoint groups. Each group contains 20 SNPs\n",
    "+ $j = 5$ groups are each assigned $1,2,...,5$ causal SNPs with effect sizes randomly chosen from $\\{−0.2,0.2\\}$. \n",
    "+ Within group correlation: $\\rho = 0.95$\n",
    "\n",
    "**We assume perfect group information**. That is, the selected groups containing 1∼5 causative SNPs are assigned maximum within-group sparsity $\\lambda_g = 1,2,...,5$. The remaining groups are assigned $\\lambda_g = 1$ (i.e. only 1 active predictor are allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define problem size\n",
    "n = 1000\n",
    "p = 10000\n",
    "dist = NegativeBinomial\n",
    "link = LogLink()\n",
    "block_size = 20                  #simulation parameter\n",
    "num_blocks = Int(p / block_size) #simulation parameter\n",
    "\n",
    "# set seed\n",
    "Random.seed!(2020)\n",
    "\n",
    "# assign group membership\n",
    "membership = collect(1:num_blocks)\n",
    "g = zeros(Int64, p + 1)\n",
    "for i in 1:length(membership)\n",
    "    for j in 1:block_size\n",
    "        cur_row = block_size * (i - 1) + j\n",
    "        g[block_size*(i - 1) + j] = membership[i]\n",
    "    end\n",
    "end\n",
    "g[end] = membership[end]\n",
    "\n",
    "#simulate correlated snparray\n",
    "x = simulate_correlated_snparray(n, p, \"./data/tmp2.bed\", prob=0.95)\n",
    "z = ones(n, 1) # the intercept\n",
    "x_float = convert(Matrix{Float64}, x, model=ADDITIVE_MODEL, center=true, scale=true)\n",
    "\n",
    "#simulate true model, where 5 groups each with 1~5 snps contribute\n",
    "true_b = zeros(p)\n",
    "true_groups = randperm(num_blocks)[1:5]\n",
    "sort!(true_groups)\n",
    "within_group = [randperm(block_size)[1:1], randperm(block_size)[1:2], \n",
    "                randperm(block_size)[1:3], randperm(block_size)[1:4], \n",
    "                randperm(block_size)[1:5]]\n",
    "correct_position = zeros(Int64, 15)\n",
    "for i in 1:5\n",
    "    cur_group = block_size * (true_groups[i] - 1)\n",
    "    cur_group_snps = cur_group .+ within_group[i]\n",
    "    start, last = Int(i*(i-1)/2 + 1), Int(i*(i+1)/2)\n",
    "    correct_position[start:last] .= cur_group_snps\n",
    "end\n",
    "for i in 1:15\n",
    "    true_b[correct_position[i]] = rand(-1:2:1) * 0.2\n",
    "end\n",
    "sort!(correct_position)\n",
    "\n",
    "# simulate phenotype\n",
    "r = 10 #nuisance parameter\n",
    "μ = GLM.linkinv.(link, x_float * true_b)\n",
    "clamp!(μ, -20, 20)\n",
    "prob = 1 ./ (1 .+ μ ./ r)\n",
    "y = [rand(dist(r, i)) for i in prob] #number of failures before r success occurs\n",
    "y = Float64.(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT without group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_float = genotype matrix in floating point numbers\n",
    "# z       = other covariates\n",
    "# y       = response vector\n",
    "\n",
    "j = 1      # 1 active group = entire dataset\n",
    "k = 15     # 15 active predictors\n",
    "ungrouped_IHT = L0_reg(x_float, z, y, j, k, NegativeBinomial(), LogLink()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHT with group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_float = genotype matrix in floating point numbers\n",
    "# z       = other covariates\n",
    "# y       = response vector\n",
    "# g       = group membership vector (simulated above)\n",
    "\n",
    "j = 5                           # maximum number of active groups\n",
    "dist = NegativeBinomial()       # distribution\n",
    "link = LogLink()                # link function\n",
    "\n",
    "# within-group sparsity for each group\n",
    "max_group_snps = ones(Int, num_blocks) \n",
    "max_group_snps[true_groups] .= collect(1:5)\n",
    "\n",
    "# run grouped IHT\n",
    "grouped_IHT = L0_reg(x_float, z, y, j, max_group_snps, NegativeBinomial(), LogLink(), group=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check variable selection against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model = DataFrame(\n",
    "    correct_positions = correct_position,\n",
    "    ungrouped_IHT_positions = findall(!iszero, ungrouped_IHT.beta),\n",
    "    grouped_IHT_positions = findall(!iszero, grouped_IHT.beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check estimated parameters against true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_position = findall(!iszero, true_b)\n",
    "compare_model = DataFrame(\n",
    "    position = correct_position,\n",
    "    correct_β = true_b[correct_position],\n",
    "    ungrouped_IHT_β = ungrouped_IHT.beta[correct_position], \n",
    "    grouped_IHT_β = grouped_IHT.beta[correct_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion:** by asking for \"top entries\" in each group, we (somewhat) disentangle the correlation structure in our data and achieved better model selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More examples:\n",
    "\n",
    "Please visit our [documentation](https://openmendel.github.io/MendelIHT.jl/latest/).\n",
    "\n",
    "## Other functionalities\n",
    "\n",
    "+ Built-in support for [PLINK binary files](https://www.cog-genomics.org/plink/1.9/input#bed) via [SnpArrays.jl](https://github.com/OpenMendel/SnpArrays.jl) and [VCF files](https://en.wikipedia.org/wiki/Variant_Call_Format) via [VCFTools.jl](https://github.com/OpenMendel/VCFTools.jl).\n",
    "+ Out-of-the-box parallel computing routines for `q-fold` cross-validation.\n",
    "+ Fits a variety of generalized linear models with any choice of link function.\n",
    "+ Computation directly on raw genotype files.\n",
    "+ Efficient handlings for non-genetic covariates.\n",
    "+ Optional acceleration (debias) step to dramatically improve speed.\n",
    "+ Ability to explicitly incorporate weights for predictors.\n",
    "+ Ability to enforce within and between group sparsity. \n",
    "+ Naive genotype imputation. \n",
    "+ Estimates nuisance parameter for negative binomial regression using Newton or MM algorithm. "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
