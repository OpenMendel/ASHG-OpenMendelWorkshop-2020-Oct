{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#VarianceComponentModels.jl\" data-toc-modified-id=\"VarianceComponentModels.jl-1\">VarianceComponentModels.jl</a></span><ul class=\"toc-item\"><li><span><a href=\"#Package-Features\" data-toc-modified-id=\"Package-Features-1.1\">Package Features</a></span></li></ul></li><li><span><a href=\"#Heritability-Analysis\" data-toc-modified-id=\"Heritability-Analysis-2\">Heritability Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-files\" data-toc-modified-id=\"Data-files-2.1\">Data files</a></span></li><li><span><a href=\"#Read-in-binary-SNP-data\" data-toc-modified-id=\"Read-in-binary-SNP-data-2.2\">Read in binary SNP data</a></span></li><li><span><a href=\"#EUR_subset\" data-toc-modified-id=\"EUR_subset-2.3\"><code>EUR_subset</code></a></span></li><li><span><a href=\"#Empirical-kinship-matrix\" data-toc-modified-id=\"Empirical-kinship-matrix-2.4\">Empirical kinship matrix</a></span></li><li><span><a href=\"#Simulating-phenotypes\" data-toc-modified-id=\"Simulating-phenotypes-2.5\">Simulating phenotypes</a></span></li><li><span><a href=\"#Phenotypes\" data-toc-modified-id=\"Phenotypes-2.6\">Phenotypes</a></span></li><li><span><a href=\"#Pre-processing-data-for-heritability-analysis\" data-toc-modified-id=\"Pre-processing-data-for-heritability-analysis-2.7\">Pre-processing data for heritability analysis</a></span></li><li><span><a href=\"#Heritability-of-single-trait\" data-toc-modified-id=\"Heritability-of-single-trait-2.8\">Heritability of single trait</a></span></li><li><span><a href=\"#Multivariate-trait-analysis\" data-toc-modified-id=\"Multivariate-trait-analysis-2.9\">Multivariate trait analysis</a></span></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-2.10\">Exercise</a></span></li></ul></li><li><span><a href=\"#Testing-SNP-association-using-maximum-likelihoods-of-variance-component-models\" data-toc-modified-id=\"Testing-SNP-association-using-maximum-likelihoods-of-variance-component-models-3\">Testing SNP association using maximum likelihoods of variance component models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fit-the-null-model\" data-toc-modified-id=\"Fit-the-null-model-3.1\">Fit the null model</a></span></li><li><span><a href=\"#Fit-the-alternative-model\" data-toc-modified-id=\"Fit-the-alternative-model-3.2\">Fit the alternative model</a></span></li><li><span><a href=\"#Likelihood-ratio-test\" data-toc-modified-id=\"Likelihood-ratio-test-3.3\">Likelihood ratio test</a></span></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-3.4\">Exercise</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heritability analysis and testing SNP association using maximum likelihoods of variance component models \n",
    "\n",
    "**ASHG OpenMendel Workshop**\n",
    "\n",
    "**Juhyun Kim, juhkim111@ucla.edu**\n",
    "\n",
    "**Department of Biostatistics, UCLA**\n",
    "\n",
    "**Oct 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.5.0\n",
      "Commit 96786e22cc (2020-08-01 23:44 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  CPU: Intel(R) Core(TM) i9-9920X CPU @ 3.50GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VarianceComponentModels.jl\n",
    "\n",
    "[`VarianceComponentModels.jl`](https://github.com/OpenMendel/VarianceComponentModels.jl/) is a package that resides in [OpenMendel](https://github.com/OpenMendel) ecosystem. It implements computation routines for fitting and testing variance component model of form \n",
    "\n",
    "$$\\text{vec}(Y) \\sim \\text{Normal}(XB, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m)$$\n",
    "\n",
    "where $\\otimes$ is the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product). \n",
    "\n",
    "In this model, **data** is represented by \n",
    "\n",
    "* `Y`: `n x d` response matrix \n",
    "* `X`: `n x p` covariate matrix \n",
    "* `V=(V1,...,Vm)`: a tuple of `m` `n x n` covariance matrices\n",
    "\n",
    "and **parameters** are\n",
    "\n",
    "* `B`: `p x d` mean parameter matrix\n",
    "* `Σ=(Σ1,...,Σm)`: a tuple of `m` `d x d` variance components. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Features \n",
    "* [Heritability analysis](https://openmendel.github.io/VarianceComponentModels.jl/latest/man/heritability/#Heritability-Analysis-1) in genetics\n",
    "* Maximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters $B$ and variance component parameters $Σ$\n",
    "* Allow constraints in the mean parameters $B$\n",
    "* Choice of optimization algorithms: [Fisher scoring](https://books.google.com/books?id=QYqeYTftPNwC&lpg=PP1&pg=PA142#v=onepage&q&f=false) and [minorization-maximization algorithm](http://hua-zhou.github.io/media/pdf/ZhouHuZhouLange19VCMM.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heritability Analysis\n",
    "\n",
    "Variance component estimation can be used to estimate heritability of a quantitative trait. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data files\n",
    "\n",
    "For this analysis, we use a sample data set [`EUR_subset`](https://openmendel.github.io/SnpArrays.jl/latest/#Example-data-1) from `SnpArrays.jl`. This data set is available in the `data` folder of the package. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SnpArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/juhkim111/.julia/packages/SnpArrays/YOSme/data\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = normpath(SnpArrays.datadir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EUR_subset.bed`, `EUR_subset.bim`, and `EUR_subset.fam` is a set of Plink files in binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"/home/juhkim111/.julia/packages/SnpArrays/YOSme/data/EUR_subset.bed\"\n",
       " \"/home/juhkim111/.julia/packages/SnpArrays/YOSme/data/EUR_subset.bim\"\n",
       " \"/home/juhkim111/.julia/packages/SnpArrays/YOSme/data/EUR_subset.fam\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Glob\n",
    "readdir(glob\"EUR_subset.*\", datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in binary SNP data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [`SnpArrays.jl`](https://openmendel.github.io/SnpArrays.jl/latest) package to read in binary SNP data and compute the empirical kinship matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379×54051 SnpArray:\n",
       " 0x03  0x03  0x03  0x02  0x02  0x03  …  0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x02  0x03  0x02  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x03  0x03  0x03     0x02  0x02  0x02  0x03  0x03  0x02\n",
       " 0x03  0x03  0x03  0x00  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x00  0x03  0x03     0x02  0x02  0x02  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x03  0x03  0x03  …  0x03  0x03  0x03  0x03  0x03  0x02\n",
       " 0x02  0x03  0x03  0x02  0x02  0x03     0x03  0x03  0x02  0x02  0x03  0x03\n",
       " 0x02  0x03  0x03  0x03  0x02  0x02     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x00  0x02  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x02  0x03  0x02     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x03  0x03  …  0x03  0x03  0x02  0x02  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x02\n",
       " 0x03  0x02  0x03  0x02  0x02  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       "    ⋮                             ⋮  ⋱     ⋮                             ⋮\n",
       " 0x03  0x03  0x03  0x00  0x02  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x02  0x03     0x02  0x02  0x02  0x03  0x02  0x03\n",
       " 0x03  0x03  0x03  0x02  0x02  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x02  0x03  0x03  …  0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x00  0x00  0x03     0x02  0x02  0x02  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x03  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x03  0x03  0x03  …  0x03  0x03  0x02  0x02  0x03  0x03\n",
       " 0x03  0x03  0x03  0x00  0x03  0x03     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x02  0x03  0x03  0x02  0x00  0x02     0x03  0x03  0x03  0x03  0x03  0x03\n",
       " 0x03  0x03  0x03  0x02  0x02  0x03     0x03  0x03  0x03  0x03  0x03  0x03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in genotype data from Plink binary file\n",
    "const EUR_subset = SnpArray(SnpArrays.datadir(\"EUR_subset.bed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EUR_subset` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EUR_subset` contains **379** individuals and **54,051** SNPs. There is no missing genotype in `EUR_subset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minor allele frequencies (MAF) for each SNP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54051-element Array{Float64,1}:\n",
       " 0.09762532981530347\n",
       " 0.01319261213720313\n",
       " 0.04485488126649073\n",
       " 0.48944591029023743\n",
       " 0.32189973614775724\n",
       " 0.09102902374670185\n",
       " 0.3733509234828496\n",
       " 0.05277044854881263\n",
       " 0.0554089709762533\n",
       " 0.11345646437994727\n",
       " 0.20448548812664913\n",
       " 0.16226912928759896\n",
       " 0.27176781002638517\n",
       " ⋮\n",
       " 0.341688654353562\n",
       " 0.13192612137203164\n",
       " 0.24802110817941958\n",
       " 0.21240105540897103\n",
       " 0.12532981530343013\n",
       " 0.13192612137203164\n",
       " 0.07387862796833777\n",
       " 0.07783641160949872\n",
       " 0.13588390501319259\n",
       " 0.0554089709762533\n",
       " 0.01319261213720313\n",
       " 0.02638522427440637"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maf_EUR = maf(EUR_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of minor allele frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate a histogram of MAF\n",
    "# using Plots, PyPlot\n",
    "# gr(size=(600, 500), html_output_format=:png)\n",
    "# hist_maf = histogram(maf_EUR, xlab = \"Minor Allele Frequency (MAF)\", \n",
    "#                    ylab = \"Number of SNPs\", label=\"\")\n",
    "# png(hist_maf, \"hist_MAF.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./hist_MAF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that about 29% of SNPs have their MAF < 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2914839688442397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(!iszero, maf_EUR .< 0.05) / length(maf_EUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical kinship matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a measure of relatedness, we compute empirical kinship matrix based on all SNPs by the genetic relation matrix (GRM). If there are missing genotypes, they are imputed on the fly by drawing according to the minor allele frequencies.\n",
    "\n",
    "Kinship coefficients summarize genetic similarity between pairs of individuals. To estimate kinship coefficient $\\Phi_{ij}$ between individuals $i$ and $j$ using GRM:\n",
    "\n",
    "$$\\widehat{\\Phi}_{GRMij} = \\frac{1}{2S} \\sum_{k=1}^S \\frac{(G_{ik}-2p_k)(G_{jk}-2p_k)}{2p_k(1-p_k)},$$\n",
    "\n",
    "where \n",
    "\n",
    "* $S$: number of SNPs in this set\n",
    "* $p_k$: minor allele frequency of SNP $k$\n",
    "* $G_{ik} \\in \\{0,1,2\\}$: number of copies of minor alleles at the $k$-th SNP of the $i$-th individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379×379 Array{Float64,2}:\n",
       "  0.526913     -0.010026     -0.0012793    …   0.00536883    0.00713397\n",
       " -0.010026      0.500049      0.00147092      -0.00178778   -0.00344277\n",
       " -0.0012793     0.00147092    0.521904        -0.0109387    -0.00262695\n",
       " -0.00239381    0.00550462    0.00755985      -0.00265867   -0.000141742\n",
       " -0.00391296    0.00422806    0.0222034       -0.0107694    -0.00248895\n",
       " -0.000555581   0.000696874   0.0125771    …  -0.0100831    -0.00575495\n",
       " -0.0095376     0.00231344   -0.00259641      -0.00282701    0.000732385\n",
       " -0.00823869    0.00556861    0.0060825       -0.00911662   -0.00638629\n",
       "  0.00117402   -0.00444907   -0.0029182       -0.00244795    0.00634087\n",
       " -0.0111617     0.00436269    0.000537307     -0.00483523   -0.00621726\n",
       " -0.00252813   -0.000626719   0.00753937   …  -0.00180836    0.00714953\n",
       "  0.0112036    -0.0024306     0.00446458      -0.00983116   -0.00296109\n",
       " -0.000451414   0.00707358   -0.00620136      -0.00473171   -0.00720874\n",
       "  ⋮                                        ⋱                \n",
       "  0.00299953   -0.0113682    -0.00331268       0.00565771    0.00808339\n",
       " -0.000521854  -0.00646386   -0.00512474       0.00167572    0.00482433\n",
       "  0.000970612  -0.00430486   -0.0129335        0.00490171    0.0147362\n",
       " -0.000163565  -0.00179531   -0.0108611    …   0.000459623   0.0036255\n",
       " -0.00668885    0.00617908   -0.00415613       0.0031146    -0.00221311\n",
       "  0.00297165   -0.00743712   -0.0137732        0.0058214     0.00386105\n",
       " -0.0024849     0.00320647   -0.0127255       -0.0058388     0.00697399\n",
       " -0.00166949   -0.0086805     0.00108433       0.0173396     0.0188838\n",
       " -0.00412641    0.00783768   -0.00977001   …   0.00661336    0.00828826\n",
       "  0.00678741   -0.00598927   -0.00121965      -0.00176491   -0.00611699\n",
       "  0.00536883   -0.00178778   -0.0109387        0.492959      0.0131705\n",
       "  0.00713397   -0.00344277   -0.00262695       0.0131705     0.512193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GRM using SNPs with maf > 0.01 (default) \n",
    "Φgrm = grm(EUR_subset; method = :GRM) # classical genetic relationship matrix\n",
    "# Φgrm = grm(EUR_subset; method = :MoM) # method of moment method\n",
    "# Φgrm = grm(EUR_subset; method = :Robust) # robust method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating phenotypes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate phenotype vector from\n",
    "\n",
    "$$\\mathbf{y} \\sim \\text{Normal}(\\mathbf{1}, 0.1 \\widehat{\\Phi}_{GRM} + 0.9 \\mathbf{I})$$\n",
    "\n",
    "where $\\widehat{\\Phi}_{GRM}$ is the estimated empirical kinship matrix `Φgrm`. \n",
    "\n",
    "The data should be available in `pheno.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate `pheno.txt` \n",
    "# using LinearAlgebra, DelimitedFiles\n",
    "# Random.seed!(1234)\n",
    "# Ω = 0.1 * Φgrm + 0.9 * Matrix(1.0*I, nobs, nobs)\n",
    "# Ωchol = cholesky(Symmetric(Ω))\n",
    "# y = ones(nobs) + Ωchol.L * randn(nobs)\n",
    "# writedlm(\"pheno.txt\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the phenotype data and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379×1 Array{Float64,2}:\n",
       "  1.846582104608307\n",
       "  0.12019614558345848\n",
       "  0.5172368025545149\n",
       "  0.11933401051509984\n",
       "  1.8407354203053767\n",
       "  3.155309404417616\n",
       "  1.518422163488851\n",
       "  0.737544574135081\n",
       "  1.4904102203720164\n",
       "  0.4942945743765427\n",
       "  0.4566487030521649\n",
       "  0.9830094325553045\n",
       "  1.1241872723791884\n",
       "  ⋮\n",
       "  0.03800817892237962\n",
       "  0.7685596964598539\n",
       "  0.9285816069462199\n",
       " -1.3005655794765896\n",
       "  1.27142883079584\n",
       "  1.8149274022746835\n",
       "  2.353663701577899\n",
       "  1.3085170568729798\n",
       "  1.2023649250831836\n",
       "  2.523945778298307\n",
       "  2.339893360260807\n",
       "  0.08293644385047372"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DelimitedFiles \n",
    "pheno = readdlm(\"pheno.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of phenotype values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate histogram of phenotype values\n",
    "#hist_pheno = histogram(pheno, xlab=\"Phenotype\", ylab=\"Frequency\", label=\"\")\n",
    "#png(hist_pheno, \"hist_pheno.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](./hist_pheno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data for heritability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare variance component model fitting, we form an instance of VarianceComponentVariate. The two covariance matrices are $(2\\Phi, I)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling VarianceComponentModels [813005db-34b4-5f71-be9e-1bbf0a1d8f1c]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(:Y, :X, :V)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using VarianceComponentModels, LinearAlgebra\n",
    "# no. of observations \n",
    "nobs = size(pheno, 1)\n",
    "\n",
    "# form data as VarianceComponentVariate\n",
    "X = ones(nobs)\n",
    "EURdata = VarianceComponentVariate(pheno, X, (2Φgrm, Matrix(1.0I, nobs, nobs)))\n",
    "fieldnames(typeof(EURdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,1},Array{Float64,2}}([1.846582104608307; 0.12019614558345848; … ; 2.339893360260807; 0.08293644385047372], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], ([1.0538262213132035 -0.02005203927901296 … 0.010737654900514978 0.014267936018676418; -0.02005203927901296 1.0000975487266064 … -0.00357555339105328 -0.006885530334701236; … ; 0.010737654900514978 -0.00357555339105328 … 0.9859187797469418 0.026340992959466743; 0.014267936018676418 -0.006885530334701236 … 0.026340992959466743 1.0243852451056221], [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EURdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Heritability of single trait "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting the variance component model, we pre-compute the eigen-decomposition of $2\\Phi_{\\text{GRM}}$, the rotated responses, and the constant part in log-likelihood, and store them as a TwoVarCompVariateRotate instance, which is re-used in various variane component estimation procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Fisher scoring algorithm to fit variance component model for our trait. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.966252 seconds (2.21 M allocations: 114.370 MiB, 21.52% gc time)\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "(σ2a, σ2e) = (0.5360487493497216, 0.3986105002707737)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5360487493497216, 0.3986105002707737)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-compute eigen-decomposition \n",
    "@time EURdata_rotated = TwoVarCompVariateRotate(EURdata)\n",
    "fieldnames(typeof(EURdata_rotated))\n",
    "\n",
    "# form data set for trait \n",
    "trait_data = TwoVarCompVariateRotate(EURdata_rotated.Yrot, \n",
    "    EURdata_rotated.Xrot, EURdata_rotated.eigval, EURdata_rotated.eigvec, \n",
    "    EURdata_rotated.logdetV2)\n",
    "\n",
    "# initialize model parameters\n",
    "trait_model = VarianceComponentModel(trait_data)\n",
    "\n",
    "# estimate variance components\n",
    "_, _, _, Σcov, = mle_fs!(trait_model, trait_data; solver=:Ipopt, verbose=false)\n",
    "σ2a = trait_model.Σ[1][1] # additive genetic variance \n",
    "σ2e = trait_model.Σ[2][1] # environmental variance \n",
    "@show σ2a, σ2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additive genetic variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360487493497216"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environmental/non-genetic variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3986105002707737"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.5735231845909365\n",
       " 0.2564683288674781"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heritability and its standard error from single trait analysis\n",
    "h, hse = heritability(trait_model.Σ, Σcov)\n",
    "\n",
    "\n",
    "[h[1], hse[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run MM algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.142368 seconds (993.74 k allocations: 52.459 MiB, 1.32% gc time)\n",
      "(σ2a, σ2e) = (0.5242689405328059, 0.4101012322722893)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5242689405328059, 0.4101012322722893)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trait_model = VarianceComponentModel(trait_data)\n",
    "@time _, _, _, Σcov, = mle_mm!(trait_model, trait_data; verbose=false)\n",
    "σ2a = trait_model.Σ[1][1]\n",
    "σ2e = trait_model.Σ[2][1]\n",
    "@show σ2a, σ2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heritability and its standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.5610934036548764\n",
       " 0.2654835477241166"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h, hse = heritability(trait_model.Σ, Σcov)\n",
    "[h[1], hse[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate trait analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the joint analysis of multiple traits, go to [`VarianceComponentModels` documentation](https://openmendel.github.io/VarianceComponentModels.jl/latest/man/heritability/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Repeat the above analysis computing the empirical kinship matrix using the method of moment method or the robust method. See [SnpArrays.jl documentation](https://openmendel.github.io/SnpArrays.jl/latest/#Genetic-relationship-matrix-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Φgrm = grm(EUR_subset; method = )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing SNP association using maximum likelihoods of variance component models\n",
    "credit: [Heritability tutorial by Sarah Ji, Janet Sinsheimer and Hua Zhou](https://github.com/OpenMendel/Tutorials/blob/master/Heritability/HERITABILITY-VCexample.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to see a particular SNP has an effect on a given phenotype after accounting for relatedness among individuals. Here we fit variance component model with a single SNP *s* as fixed effect. \n",
    "\n",
    "$$\\hspace{5em}  \\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{G}_s \\gamma + \\mathbf{g} + \\mathbf{\\epsilon} \\hspace{5em} (1)$$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{ll}\n",
    "\\mathbf{g} \\sim N(\\mathbf{0}, \\sigma_g^2\\mathbf{\\Phi}) \\\\\n",
    "\\mathbf{\\epsilon} \\sim N(\\mathbf{0}, \\sigma_e^2\\mathbf{I})\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\n",
    "* $\\mathbf{y}$: phenotype \n",
    "\n",
    "\n",
    "\n",
    "and \n",
    "\n",
    "\n",
    "* Fixed effects:\n",
    "    * $\\mathbf{X}$: matrix of covariates including intercept\n",
    "    * $\\beta$: vector of covariate effects, including intercept\n",
    "    * $\\mathbf{G}_s$: genotype of SNP *s*\n",
    "    * $\\gamma$: (scalar) association parameter of interest, measuring the effect of genotype on phenotype  \n",
    "* Random effects:\n",
    "    * $\\mathbf{g}$: random vector of polygenic effects with $\\mathbf{g} \\sim N(\\mathbf{0}, \\sigma_g^2 \\mathbf{\\Phi})$\n",
    "        * $\\sigma_g^2$: additive genetic variance\n",
    "        * $\\mathbf{\\Phi}$: matrix of pairwise measures of genetic relatedness \n",
    "    * $\\epsilon$: random vector with $\\epsilon \\sim N(\\mathbf{0}, \\sigma_e^2\\mathbf{I})$\n",
    "        * $\\sigma_e^2$: non-genetic variance due to non-genetic effects assumed to be acting independently on individuals\n",
    "\n",
    "\n",
    "\n",
    "To test whether SNP *s* is associated with phenotype, we fit two models. First consider the model without SNP *s* as fixed effects (aka null model): \n",
    "\n",
    "$$\\hspace{5em}  \\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{g} + \\mathbf{\\epsilon} \\hspace{5em} (2)$$\n",
    "\n",
    "and the model with SNP *s* as fixed effects (1). Then we can compare the log likelihood to see if there is improvement in the model fit with inclusion of the SNP of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,1},Array{Float64,2}}([1.846582104608307; 0.12019614558345848; … ; 2.339893360260807; 0.08293644385047372], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], ([1.0538262213132035 -0.02005203927901296 … 0.010737654900514978 0.014267936018676418; -0.02005203927901296 1.0000975487266064 … -0.00357555339105328 -0.006885530334701236; … ; 0.010737654900514978 -0.00357555339105328 … 0.9859187797469418 0.026340992959466743; 0.014267936018676418 -0.006885530334701236 … 0.026340992959466743 1.0243852451056221], [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using VarianceComponentModels\n",
    "# null data model has two variance components but no SNP fixed effects\n",
    "# form data as VarianceComponentVariate matrix \n",
    "X = ones(nobs)\n",
    "nulldata = VarianceComponentVariate(pheno, X, (2Φgrm, Matrix(1.0I, nobs, nobs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.0], ([1.0], [1.0]), Array{Float64}(undef,0,1), Char[], Float64[], -Inf, Inf)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullmodel = VarianceComponentModel(nulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.13.2, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.6731456e+02 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n",
      "   5  5.2391619e+02 0.00e+00 4.25e-03 -11.0 2.02e-03    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  10  5.2391619e+02 0.00e+00 1.92e-05 -11.0 1.17e-05    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  15  5.2391619e+02 0.00e+00 1.14e-07 -11.0 6.93e-08    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "\n",
      "Number of Iterations....: 18\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   5.1219287461557428e+02    5.2391619033590621e+02\n",
      "Dual infeasibility......:   5.2486628407216991e-09    5.3687967485538555e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   5.2486628407216991e-09    5.3687967485538555e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 19\n",
      "Number of objective gradient evaluations             = 19\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 18\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.065\n",
      "Total CPU secs in NLP function evaluations           =      0.408\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "  0.817065 seconds (1.51 M allocations: 78.694 MiB, 3.90% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-523.9161903359062, VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.9900140588281151], ([0.5360487493497216], [0.3986105002707737]), Array{Float64}(undef,0,1), Char[], Float64[], -Inf, Inf), ([0.28721820980494434], [0.2789237673497641]), [0.08249430004355703 -0.07781584431646675; -0.07781584431646676 0.07779846799258533], [0.032430583478836504], [0.001051742744777783])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time nulllogl, nullmodel, = fit_mle!(nullmodel, nulldata; algo=:FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model log-likelihood (no SNP effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-523.9161903359062"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulllogl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model mean effects (a grand mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float64,2}:\n",
       " 0.9900140588281151"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullmodel.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model additive genetic variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float64,2}:\n",
       " 0.5360487493497216"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullmodel.Σ[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null model environmental variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float64,2}:\n",
       " 0.3986105002707737"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullmodel.Σ[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the alternative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,2},Array{Float64,2}}([1.846582104608307; 0.12019614558345848; … ; 2.339893360260807; 0.08293644385047372], [1.0 3.0; 1.0 3.0; … ; 1.0 2.0; 1.0 3.0], ([1.0538262213132035 -0.02005203927901296 … 0.010737654900514978 0.014267936018676418; -0.02005203927901296 1.0000975487266064 … -0.00357555339105328 -0.006885530334701236; … ; 0.010737654900514978 -0.00357555339105328 … 0.9859187797469418 0.026340992959466743; 0.014267936018676418 -0.006885530334701236 … 0.026340992959466743 1.0243852451056221], [1.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 0.0 … 0.0 1.0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snp_vec = convert(Vector{Float64}, EUR_subset[:, 10]) \n",
    "Xalt = [ones(nobs) snp_vec]\n",
    "altdata = VarianceComponentVariate(pheno, Xalt, (2Φgrm, Matrix(1.0I, nobs, nobs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.0; 0.0], ([1.0], [1.0]), Array{Float64}(undef,0,2), Char[], Float64[], -Inf, Inf)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altmodel = VarianceComponentModel(altdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.13.2, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.6689443e+02 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n",
      "   5  5.2302301e+02 0.00e+00 1.54e-03 -11.0 9.40e-04    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "  10  5.2302301e+02 0.00e+00 2.88e-06 -11.0 2.06e-06    -  1.00e+00 1.00e+00f  1 MaxSA\n",
      "  15  5.2302301e+02 0.00e+00 6.40e-09 -11.0 4.58e-09    -  1.00e+00 1.00e+00f  1 MaxS\n",
      "\n",
      "Number of Iterations....: 15\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   5.0937186058543369e+02    5.2302300937937900e+02\n",
      "Dual infeasibility......:   6.4017736552338296e-09    6.5733409746619481e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   6.4017736552338296e-09    6.5733409746619481e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 16\n",
      "Number of objective gradient evaluations             = 16\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 15\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.531\n",
      "Total CPU secs in NLP function evaluations           =      0.064\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "  0.456182 seconds (713.07 k allocations: 40.099 MiB, 3.06% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-523.023009379379, VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}([0.6430890987166976; 0.12582254534184575], ([0.5131884765245557], [0.4165771366329441]), Array{Float64}(undef,0,2), Char[], Float64[], -Inf, Inf), ([0.2881234472862608], [0.280507967380032]), [0.08301512087611872 -0.07854568365271096; -0.07854568365271092 0.0786847197636771], [0.2611312941282091; 0.09394055576183906], [0.06818955277307327 -0.024332309439580764; -0.02433230943958076 0.008824828016843193])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time altlogl, altmodel, = fit_mle!(altmodel, altdata; algo=:FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative model log-likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-523.023009379379"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altlogl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative model mean effects (a grand mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×1 Array{Float64,2}:\n",
       " 0.6430890987166976\n",
       " 0.12582254534184575"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altmodel.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative model additive genetic variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float64,2}:\n",
       " 0.5131884765245557"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altmodel.Σ[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative model environmental variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float64,2}:\n",
       " 0.4165771366329441"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altmodel.Σ[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood ratio test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use likelihood ratio test (LRT) to test the goodness-of-fit between two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our likelihood ratio test statistic is 1.786 (distributed chi-squared), with one degree of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7863619130544066"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "LRT = 2(altlogl - nulllogl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated p-value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1813700566785783"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval = ccdf(Chisq(1), LRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that adding this SNP as a covariate to the model does not fit significantly better than the null model. In other words, the SNP does not explain more of the variation in our trait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use minorization-maximization algorithm (`algo=:MM`) to find MLEs of both null model and alternative model. Then conduct the likelihood ratio test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "293px",
    "width": "362px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
